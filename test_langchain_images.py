#!/usr/bin/env python3
"""
Test script specifically for LangChain implementations with image support
Tests both simple and full LangChain versions with multimodal documents.
"""

import logging
from simple_langchain_rag import create_simple_rag, create_document

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def test_simple_langchain_with_images():
    """Test the simple LangChain RAG with image documents."""
    print("ğŸ§ª Testing Simple LangChain RAG with Images")
    print("=" * 50)
    
    try:
        # Create RAG system
        print("ğŸ”§ Creating Simple LangChain RAG system...")
        rag = create_simple_rag("image_test_collection")
        print("âœ… System created successfully")
        
        # Create test documents with images
        print("\nğŸ“š Creating test documents with images...")
        
        image_documents = [
            create_document(
                id="langchain_img_1",
                text="This document demonstrates LangChain compatibility with image processing. The system can handle both text and visual content seamlessly.",
                image_url="https://via.placeholder.com/300x200/blue/white?text=LangChain+Compatible",
                category="Technology",
                topic="LangChain",
                has_image=True
            ),
            create_document(
                id="langchain_img_2", 
                text="Multimodal RAG systems combine text retrieval with image understanding for comprehensive document processing.",
                image_url="https://via.placeholder.com/400x300/green/white?text=Multimodal+RAG",
                category="AI",
                topic="Multimodal AI",
                has_image=True
            ),
            create_document(
                id="langchain_text_only",
                text="This is a text-only document for comparison with multimodal documents in the LangChain system.",
                category="Technology",
                topic="Text Processing",
                has_image=False
            )
        ]
        
        # Add documents to the system
        print(f"ğŸ“ Adding {len(image_documents)} documents (including images)...")
        success_count = 0
        
        for doc in image_documents:
            try:
                success = rag.add_document(doc)
                if success:
                    success_count += 1
                    status = "âœ…" if doc.image_url else "ğŸ“„"
                    print(f"  {status} Added: {doc.id} ({'with image' if doc.image_url else 'text only'})")
                else:
                    print(f"  âŒ Failed to add: {doc.id}")
            except Exception as e:
                print(f"  âš ï¸ Error adding {doc.id}: {e}")
        
        print(f"ğŸ“Š Successfully added {success_count}/{len(image_documents)} documents")
        
        # Get system statistics
        print("\nğŸ“ˆ System Statistics:")
        stats = rag.get_stats()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        # Test search functionality
        print("\nğŸ” Testing Search with Multimodal Content:")
        
        search_queries = [
            "LangChain image processing",
            "multimodal RAG systems", 
            "text and visual content",
            "document processing"
        ]
        
        for query in search_queries:
            print(f"\nğŸ” Query: '{query}'")
            results = rag.search(query, k=3)
            
            print(f"  Found {results['num_results']} results:")
            for i, result in enumerate(results['results']):
                metadata = result['metadata']
                similarity = result.get('similarity_score', 0.0)
                has_image = metadata.get('has_image', False)
                
                print(f"    {i+1}. Score: {similarity:.3f} {'ğŸ–¼ï¸' if has_image else 'ğŸ“„'}")
                print(f"       ID: {metadata.get('original_id', metadata.get('id', 'Unknown'))}")
                print(f"       Topic: {metadata.get('topic', 'N/A')}")
                print(f"       Content: {result['content'][:100]}...")
                if has_image:
                    print(f"       Image: {metadata.get('image_url', 'N/A')}")
                print()
        
        # Test Q&A functionality with multimodal context
        print("\nâ“ Testing Q&A with Multimodal Context:")
        
        qa_questions = [
            "How does LangChain work with images?",
            "What is multimodal RAG?",
            "Can the system process both text and images?"
        ]
        
        for question in qa_questions:
            print(f"\nâ“ Question: {question}")
            try:
                result = rag.query(question)
                print(f"ğŸ¤– Answer: {result['answer'][:200]}...")
                
                sources_with_images = 0
                for source in result['source_documents']:
                    if source['metadata'].get('has_image', False):
                        sources_with_images += 1
                
                print(f"ğŸ“š Sources: {len(result['source_documents'])} total, {sources_with_images} with images")
                
            except Exception as e:
                print(f"âš ï¸ Q&A failed: {e}")
        
        # Test LangChain component access
        print("\nğŸ”— Testing LangChain Component Access:")
        
        try:
            # Test retriever access
            retriever = rag.retriever
            print("âœ… Retriever accessible")
            
            # Test vector store access
            vectorstore = rag.vectorstore
            print("âœ… Vector store accessible")
            
            # Test direct retrieval
            docs = retriever.get_relevant_documents("test query")
            print(f"âœ… Direct retrieval works: {len(docs)} documents")
            
            # Test embeddings
            embeddings = rag.embeddings
            test_embedding = embeddings.embed_query("test")
            print(f"âœ… Embeddings work: {len(test_embedding)} dimensions")
            
        except Exception as e:
            print(f"âš ï¸ Component access error: {e}")
        
        print("\nğŸ‰ Simple LangChain RAG with images test completed!")
        return True
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False

def test_image_processing_capabilities():
    """Test specific image processing capabilities."""
    print("\nğŸ–¼ï¸ Testing Image Processing Capabilities")
    print("=" * 40)
    
    try:
        rag = create_simple_rag("image_processing_test")
        
        # Test different image types
        test_images = [
            {
                "url": "https://via.placeholder.com/150x150/red/white?text=Red+Square",
                "description": "Red square image"
            },
            {
                "url": "https://via.placeholder.com/300x200/blue/white?text=Blue+Rectangle", 
                "description": "Blue rectangle image"
            },
            {
                "url": "https://via.placeholder.com/200x300/green/white?text=Green+Portrait",
                "description": "Green portrait image"
            }
        ]
        
        print("ğŸ¨ Testing different image formats and sizes...")
        
        for i, img_info in enumerate(test_images):
            doc = create_document(
                id=f"image_test_{i+1}",
                text=f"Test document with {img_info['description']} for format testing.",
                image_url=img_info['url'],
                image_type=img_info['description']
            )
            
            try:
                success = rag.add_document(doc)
                if success:
                    print(f"  âœ… {img_info['description']}: Added successfully")
                else:
                    print(f"  âš ï¸ {img_info['description']}: Addition failed")
            except Exception as e:
                print(f"  âŒ {img_info['description']}: Error - {e}")
        
        # Test search across different image types
        print("\nğŸ” Testing search across different image types...")
        results = rag.search("image format testing", k=5)
        
        print(f"Found {results['num_results']} results:")
        for i, result in enumerate(results['results']):
            metadata = result['metadata']
            print(f"  {i+1}. {metadata.get('image_type', 'Unknown type')}")
            print(f"     Content: {result['content'][:80]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Image processing test failed: {e}")
        return False

def main():
    """Main test function."""
    print("ğŸš€ LangChain Multimodal RAG Image Testing")
    print("=" * 60)
    
    # Test simple LangChain with images
    simple_test_passed = test_simple_langchain_with_images()
    
    if simple_test_passed:
        print("\n" + "=" * 60)
        
        # Test image processing capabilities
        image_test_passed = test_image_processing_capabilities()
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Test Summary:")
        print(f"  Simple LangChain with Images: {'âœ… PASSED' if simple_test_passed else 'âŒ FAILED'}")
        print(f"  Image Processing Capabilities: {'âœ… PASSED' if image_test_passed else 'âŒ FAILED'}")
        
        if simple_test_passed and image_test_passed:
            print("\nğŸ‰ All LangChain image tests passed!")
            print("\nğŸ’¡ Key Findings:")
            print("  âœ… LangChain compatibility maintained with image processing")
            print("  âœ… Multimodal documents work with LangChain components")
            print("  âœ… Search functionality works across text and image content")
            print("  âœ… Q&A chains can access multimodal context")
            print("  âœ… All LangChain components (retriever, vectorstore) accessible")
        else:
            print("\nâš ï¸ Some tests had issues, but basic functionality works")
    else:
        print("\nâŒ Basic LangChain image test failed")
    
    print("\nğŸ”— Integration Ready:")
    print("  - Use with any LangChain LLM (OpenAI, Anthropic, Ollama)")
    print("  - Compatible with LangChain chains and agents")
    print("  - Supports both text-only and multimodal documents")
    print("  - Maintains metadata through the processing pipeline")

if __name__ == "__main__":
    main()
